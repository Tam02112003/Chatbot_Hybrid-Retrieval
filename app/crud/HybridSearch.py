import os
import re

from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from app.pkgs.model import call_gemma3n_api, call_llm_studio_api
from app.pkgs.Neo4jManager import neo4j_graph

# -------- Tr√≠ch xu·∫•t triples t·ª´ vƒÉn b·∫£n
def extract_triples_from_text(text: str):
    text = text.strip()[:1000]
    prompt = f"""
    Tr√≠ch xu·∫•t c√°c m·ªëi quan h·ªá (triple) t·ª´ ƒëo·∫°n vƒÉn sau, theo d·∫°ng:
    (Ch·ªß ng·ªØ, Quan h·ªá, T√¢n ng·ªØ)
    
    Kh√¥ng c·∫ßn gi·∫£i th√≠ch g√¨ th√™m, ch·ªâ c·∫ßn tr·∫£ v·ªÅ c√°c triple theo ƒë·ªãnh d·∫°ng
    VƒÉn b·∫£n:
    {text}
    K·∫øt qu·∫£:
    """.strip()

    try:
        output = call_gemma3n_api(prompt)
        print(f'üì§ Output t·ª´ Gemma3n:\n', output)
        triple_pattern = r"[\*\-]?\s*\(([^,]+?),\s*([^,]+?),\s*([^)]+?)\)"
        matches = re.findall(triple_pattern, output)

        triples = [tuple(p.strip().replace("'", "\\'") for p in match) for match in matches]
        return triples
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói khi g·ªçi LLM: {e}")
        return []



def semantic_search(question: str, top_k: int = 3):
    if not os.path.exists("app/faiss_index"):
        print("‚ö†Ô∏è Ch∆∞a c√≥ index FAISS, vui l√≤ng upload file tr∆∞·ªõc.")
        return []

    embedding_model = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )
    vectorstore = FAISS.load_local("app/faiss_index", embedding_model, allow_dangerous_deserialization=True)
    return vectorstore.similarity_search(question, k=top_k)

# -------- Tr√≠ch xu·∫•t th·ª±c th·ªÉ t·ª´ c√¢u h·ªèi
def extract_entity_from_question(question: str) -> str:
    prompt = f"""
T·ª´ c√¢u h·ªèi sau, tr√≠ch xu·∫•t **t√™n ƒë·ªëi t∆∞·ª£ng ch√≠nh** (v√≠ d·ª• t·ªï ch·ª©c, s·∫£n ph·∫©m, d·ªãch v·ª•,...)

V√≠ d·ª•:
C√¢u h·ªèi: "HDBank cung c·∫•p d·ªãch v·ª• g√¨?" ‚Üí HDBank
C√¢u h·ªèi: "D·ªãch v·ª• ki·ªÅu h·ªëi c√≥ nh·ªØng ∆∞u ƒë√£i n√†o?" ‚Üí D·ªãch v·ª• ki·ªÅu h·ªëi

C√¢u h·ªèi: "{question}"
ƒê·ªëi t∆∞·ª£ng:
""".strip()

    try:
        response = call_gemma3n_api(prompt).strip()
        return response
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói khi t√°ch entity: {e}")
        return ""

# -------- Truy v·∫•n quan h·ªá t·ª´ entity
def query_relations_from_entity(entity: str):
    cypher = f"""
    MATCH (e:Entity)-[r]->(o:Entity)
    WHERE toLower(e.name) CONTAINS '{entity.lower()}'
    RETURN e.name AS ChuNgu, type(r) AS QuanHe, o.name AS TanNgu
    LIMIT 50
    """
    try:
        return neo4j_graph.query(cypher)
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói Cypher: {e}")
        return []

# -------- Truy v·∫•n
def ask_question(question: str):
    entity = extract_entity_from_question(question)
    graph_results = query_relations_from_entity(entity) if entity else []

    semantic_results = semantic_search(question)

    context_chunks = "\n".join(
        f"- {doc.page_content[:300]}" for doc in semantic_results
    ) if semantic_results else ""

    graph_info = "\n".join(
        f"- {r['ChuNgu']} {r['QuanHe']} {r['TanNgu']}" for r in graph_results
    ) if graph_results else ""

    # T·∫°o prompt t·ªïng h·ª£p t·ª´ 2 ngu·ªìn
    prompt = f"""
Ng∆∞·ªùi d√πng h·ªèi: "{question}"

Th√¥ng tin t√¨m ƒë∆∞·ª£c t·ª´ graph:
{graph_info if graph_info else '(Kh√¥ng c√≥)'}

C√°c ƒëo·∫°n vƒÉn li√™n quan t·ª´ semantic search:
{context_chunks if context_chunks else '(Kh√¥ng c√≥)'}

N·∫øu trong ƒë√≥ c√≥ ƒë∆∞·ªùng link tr√πng nhau th√¨ ch·ªâ gi·ªØ m·ªôt
H√£y tr·∫£ l·ªùi m·ªôt c√°ch th√¢n thi·ªán nh∆∞ m·ªôt tr·ª£ l√Ω ·∫£o c·ªßa c√¥ng ty HDBank.
""".strip()

    try:
        return "üí¨ " + call_gemma3n_api(prompt).strip()
    except:
        return f"{graph_info}\n{context_chunks}"



